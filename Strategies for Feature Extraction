# Loading packages
from google.colab.patches import cv2_imshow
from google.colab import files
import cv2
import matplotlib.pyplot as plt 
from PIL import Image, ImageDraw
import numpy as np
from math import sqrt
from imutils import contours
from skimage import measure
import numpy as np
import argparse
import imutils
import cv2

# Loading image
input = files.upload()

# Uploading image and converting to grey scale
input_image = cv2.imread('16_right.jpeg')
input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)
plt.imshow(input_image)

# Downsampling the image and comparing the resolution

downsample = cv2.resize(input_image, None, fx=0.035, fy=0.035, interpolation = cv2.INTER_CUBIC)

plt.figure(figsize=(15,12))

plt.subplot(121)
plt.imshow(input_image, cmap = 'gray')
plt.title('Original Image')

plt.subplot(122)
plt.imshow(downsample, cmap = 'gray')
plt.title('Downsampled Image')
plt.show()

alpha = 1.5 # Contrast control (1.0-3.0)
beta = 0 # Brightness control (0-100)

# Increasing the constrast of the image
increased_contrast = cv2.convertScaleAbs(np.float32(input_image), alpha=alpha, beta=beta)
plt.imshow(increased_contrast)

filename = '16_right_edited.jpeg'
  
# Saving the image 
cv2.imwrite(filename, increased_contrast) 

# Strategy 1

image = cv2.imread("16_right_edited.jpeg")
output = image.copy()
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
plt.imshow(gray)

# Using the HoughCircles Package
circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 10, 50,
                           minRadius=50,maxRadius=200)
print(circles)

# Hardcoding circle coordinates
cv2.circle(output, (1401, 1424), 231, (0, 255, 0), 4)

# Showing the resulting image
plt.imshow(output)

# Strategy 2

from PIL import Image, ImageDraw
from math import sqrt

# Load image:
input_i = Image.open("16_right_edited.jpeg")
print(input_i.size)

# Finding out the resolution and dimensions of the image
pixels = input_i.load()
size = input_i.size

# Sobel kernels
# Convolution uses kernels to extract features from an image. 
# A kernel is a matrix of weights which are multiplied with the input to extract relevant features
# Sobel kernels are used in edge detection image processing. 

kernel_y = [[-1, 0, 1],
            [-2, 0, 2],
            [-1, 0, 1]]
kernel_x = [[-1, -2, -1],
            [0, 0, 0],
            [1, 2, 1]]

# Create output image
output_image = Image.new("RGB", size)
draw = ImageDraw.Draw(output_image)

# Computing convolution between intensity and kernels
for x in range(1, input_i.width - 1):
    for y in range(1, input_i.height - 1):
        mag_x, mag_y = 0, 0
        for a in range(3):
            for b in range(3):
                xn = x + a - 1
                yn = y + b - 1
                intensity = sum(pixels[xn, yn])
                mag_x += intensity * kernel_x[a][b]
                mag_y += intensity * kernel_y[a][b]

        # Draw in black and white the magnitude
        color = int(sqrt(mag_x**2 + mag_y**2))
        draw.point((x, y), (color, color, color))
    
output_image.save('sobel.png')

img_2 = cv2.imread('sobel.png')
img_2 = cv2.cvtColor(img_2, cv2.COLOR_BGR2RGB)
plt.imshow(img_2)

# Strategy 3

input_image = cv2.imread('16_right.jpeg')
input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)
plt.imshow(input_image)

orig = input_image.copy()
gray = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)

gray = cv2.GaussianBlur(gray, (251, 251), 0)

(minVal, maxVal, minLoc, maxLoc) = cv2.minMaxLoc(gray)

cv2.circle(orig, maxLoc, 251, (255, 0, 0), 2)
plt.imshow(orig)

# Strategy 4

# Loading Image
image = cv2.imread("16_right_edited.jpeg")

# Converting Image to grayscale 
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Smoothening Image to reduce background noise
smoothened = cv2.GaussianBlur(gray, (11, 11), 0)

# Brightest regions in the image are seen by implementing thresholds 
# Here, any pixels with a value >= 200 are set to 255 (white). On the other hand, values < 200 are set to 0 (black).
threshold = cv2.threshold(smoothened, 200, 255, cv2.THRESH_BINARY)[1]

# More background noise is removed through a series of dilations and erosions
threshold = cv2.erode(threshold, None, iterations=2)
threshold = cv2.dilate(threshold, None, iterations=4)

# Performing connected-component analysis
# Analysis is performed using the scikit-image library. 
# The labels variable returned from measure.label has the exact same dimensions as the threshold image
# Here, the labels store a unique integer for each blob in threshold. 
labels = measure.label(threshold, neighbors=8, background=0)

# initialize mask to subset only the large blobs
mask = np.zeros(threshold.shape, dtype="uint8")

# loop over the unique labels
for label in np.unique(labels):
	# When the label = 0, it is apparent that the background region is being examined and can thus be ignored
	if label == 0:
		continue
	
  # otherwise, construct the label mask and count the number of pixels 
	labelMask = np.zeros(threshold.shape, dtype="uint8")
	labelMask[labels == label] = 255
	numPixels = cv2.countNonZero(labelMask)
	
  # if the number of pixels in the component is sufficiently large, then add it to our mask of "large blobs"
	if numPixels > 300:
		mask = cv2.add(mask, labelMask)

# find the contours in the mask, then sort them from left to right

cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
cnts = imutils.grab_contours(cnts)
#cnts = contours.sort_contours(cnts)[0]

# loop over the contours
for (i, c) in enumerate(cnts):
	# draw the bright spot on the image
	(x, y, w, h) = cv2.boundingRect(c)
	((cX, cY), radius) = cv2.minEnclosingCircle(c)
	cv2.circle(image, (int(cX), int(cY)), int(radius),(0, 0, 255), 3)
	cv2.putText(image, "#{}".format(i + 1), (x, y - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)

# show the output image
plt.imshow(image)







